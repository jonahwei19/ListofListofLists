# Risk characterization evidence

**Tag**: Science

## What it is
Robust research characterizing AI risks empirically with high validity, focused on evidence usable for policy decisions. Creates benchmarks establishing clear quantitative thresholds for risks. Provides governments with clear criteria for when to intervene, producing credible empirical evidence enabling appropriate action when AI capabilities increase.

## Why it matters
- Policy decisions require evidence, not speculation
- Current risk claims range from dismissive to apocalyptic with little empirical grounding
- Validated metrics give policymakers actionable intervention criteria rather than choosing between competing narratives

## Current state
- **Status**: Research
- **Bottlenecks**: Not specified

## Who's working on it
- Not specified

## Sources
- [Peregrine 2025 #48: Characterizing AI Risks with Evidence](../sources/peregrine-2025/interventions/peregrine-048.md)
