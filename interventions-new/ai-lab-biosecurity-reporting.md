# AI Lab Biosecurity Reporting

**Tag**: Security

## What it is
A dedicated organization to receive, analyze, and respond to biosecurity concerns detected by AI labs. When frontier AI systems detect potential biological threat development attempts (dangerous queries, capability uplift requests, suspicious usage patterns), labs currently have no clear pathway for reporting. This creates an information silo where each lab sees fragments of potential threats but no one has the full picture.

The organization would:
- Receive biorisk reports from participating AI labs
- Aggregate and analyze patterns across labs (coordination problems visible only at aggregate level)
- Interface with biosecurity agencies and law enforcement as appropriate
- Develop and maintain response protocols
- Provide guidance back to labs on emerging threat patterns

## Why it matters
- AI labs are frontline sensors for bio-misuse attempts but their intelligence is currently lost or siloed
- Aggregated data reveals coordination patterns invisible to individual labs
- Response pathways turn detection into prevention
- The gap exists now and worsens as AI biology capabilities improve
- Without this, detection happens but nothing follows

## Current state
- **Status**: Gap identified
- **Bottlenecks**:
  - No existing organization fills this role
  - Unclear which institution should operate it (government, nonprofit, international)
  - Liability concerns for labs sharing information
  - Classification and secrecy issues for sensitive reports
  - Competition concerns between labs about sharing usage data

## Who's working on it
- Not specified (gap)

## Related
This differs from general [[ai-incident-reporting]] in its specific focus on biological threats, which require specialized expertise to assess and different response pathways (biosecurity agencies vs general safety regulators).

## Sources
- [Atlas AI Resilience Gap Map: Biothreat Reporting](../sources/atlas-ai-resilience/proposals/biothreat-reporting.md)
