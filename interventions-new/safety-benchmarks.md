# Safety benchmark development

**Tag**: Science

## What it is
Comprehensive high-effort benchmarks for evaluating AI safety and security. Many safety benchmarks have been defunded or discontinued. Develops rigorous, transparent methodologies for assessing various dimensions of AI safety. Aims to provide common language for discussing safety progress across different models and organizations.

## Why it matters
- Without agreed benchmarks, no way to measure safety progress or compare approaches
- Labs can claim models are "safe" without standard meaning
- High-quality benchmarks create accountability with objective measures enabling comparison across models and time

## Current state
- **Status**: Idea
- **Bottlenecks**: Previous benchmarks defunded/discontinued; skepticism about benchmark validity for actual safety

## Who's working on it
- Not specified (many safety benchmarks discontinued)

## Sources
- [Peregrine 2025 #50: Safety Benchmark Development](../sources/peregrine-2025/interventions/peregrine-050.md)
