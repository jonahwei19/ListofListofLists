# Loss of control threat modeling

**Tag**: Security

## What it is
Extensive threat-modeling experiments for loss-of-control scenarios, including honeypot experiments in realistic sandboxes with AI systems interacting with each other. Simulations reveal whether systems develop concerning behaviors like cooperation for deception or capability to jailbreak other systems.

## Why it matters
- We don't know what loss of control would actually look like or how it would unfold
- Concrete threat modeling identifies specific failure modes and tests proposed defenses
- May reveal unexpected risks like emergent cooperation between AI systems against oversight

## Current state
- **Status**: Research
- **Bottlenecks**: Not specified

## Who's working on it
- Not specified

## Sources
- [Peregrine 2025 #27: Loss of Control Threat Modeling](../sources/peregrine-2025/interventions/peregrine-027.md)
