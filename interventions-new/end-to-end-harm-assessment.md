# End-to-end harm assessment

**Tag**: Security

## What it is
Comprehensive evaluations of harmful AI capabilities using full capability assessment frameworks rather than multiple-choice tasks. Evaluates "end-to-end harmful capability manifestation": not just whether AI can answer questions about harmful topics, but whether it can assist with ideation, planning, and execution of potentially dangerous activities across sequential tasks.

## Why it matters
- Current evals test whether models know dangerous information, not whether they can help execute harmful plans
- A model might score low on biosecurity knowledge but still guide someone through an attack
- End-to-end assessment reveals actual harmful capability, not just knowledge

## Current state
- **Status**: Research
- **Bottlenecks**: Not specified

## Who's working on it
- Not specified

## Sources
- [Peregrine 2025 #43: End-to-End Harm Assessment](../sources/peregrine-2025/interventions/peregrine-043.md)
