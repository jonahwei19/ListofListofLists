# AI conflict game theory institute

**Tag**: Science

## What it is
A research institute—analogous to RAND Corporation's Cold War strategists—analyzing multi-agent AI dynamics through rigorous game theory. Core research areas:

- **Dynamic coalition formation**: How AI agents form, maintain, and dissolve strategic alliances
- **Principal-agent problems**: Governance challenges when AI agents act on behalf of humans or other AI
- **Emergent collusion detection**: Early-warning systems for unintended coordination between agents
- **Sabotage and adversarial dynamics**: Strategic behavior in competitive multi-agent environments
- **Partial observability games**: Decision-making when agents have incomplete information about others

## Why it matters
- **Alignment insufficiency**: Aligning individual AI systems with human goals may not guarantee safety in multi-agent environments—emergent risks arise from interactions
- **Unprecedented complexity**: Advanced AI agents will create multi-agent systems of unprecedented scale and speed
- **Intuition failure**: High-stakes multi-agent scenarios (AI arms races, market dynamics, infrastructure control) require formal frameworks, not intuition
- **Cooperation infrastructure**: Existing norms, laws, and institutions weren't designed for AI-to-AI or AI-to-human game-theoretic dynamics

## Current state
- **Status**: Research (emerging field)
- **Recent developments (2025)**:
  - Cooperative AI Foundation released major technical report on multi-agent risks with 50+ researchers from DeepMind, Anthropic, CMU, Harvard
  - Report includes risk taxonomy, case studies (coordination failures in driving, misinformation spread, overseer manipulation)
  - GameSec 2025 conference on game theory and AI for security
  - Foresight Institute RFP for "Safe Multi-Agent Scenarios" research
- **Bottlenecks**: Recruiting theorists of sufficient caliber; institutional home; access to frontier systems; bridging theory-practice gap

## Who's working on it
- **Cooperative AI Foundation**: Research director Lewis Hammond (Oxford), 2025 PhD Fellows program, multi-agent risk report
- **Carnegie Mellon FOCAL Lab**: Foundations of Cooperative AI—algorithmic game theory, RL cooperation
- **DeepMind, Anthropic**: Contributors to multi-agent risk research
- **Foresight Institute**: Funding safe multi-agent scenarios research
- **GameSec conference community**: Annual conference on game theory for security

## Sources
- [Peregrine 2025 #193: Game Theoretic AI Conflict Analysis](../sources/peregrine-2025/interventions/peregrine-193.md)
