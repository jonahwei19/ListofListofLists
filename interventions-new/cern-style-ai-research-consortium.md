# CERN-style AI research consortium

**Tag**: Society

## What it is
International AI development consortium allowing unified research without competitive pressures, similar to CERN or Intelsat.

**Mechanism**:
- Neutral international facility with massive computational resources
- Member nations contribute funding, receive access to research results
- Safety research requiring extraordinary compute conducted here (impossible for any single lab)
- Technical safety decisions made by consortium, not individual corporate/national actors
- Controlled testbed for evaluating advanced AI under rigorous conditions
- Defers difficult coordination problems to the project itself rather than negotiating across disparate labs

**Why CERN model**: CERN enables experiments impossible elsewhere by pooling resources. Advanced AI safety research similarly requires resources no single actor can provide.

## Why it matters
- Competitive dynamics between labs and nations undermine safety work
- Collaborative safety research requiring massive compute currently impossible
- Neutral testbed could enable rigorous evaluations no single lab would undertake alone
- Removes competitive pressure that drives corner-cutting on safety

## Current state
- **Status**: Idea
- **Bottlenecks**: Funding at required scale; geopolitical tensions; China participation particularly challenging; governance structure unclear; dramatically expands government role in technology decisions

## Who's working on it
- **No dedicated organization identified** (idea stage)

## Sources
- [Peregrine 2025 #116: CERN for AI](../sources/peregrine-2025/interventions/peregrine-116.md)
