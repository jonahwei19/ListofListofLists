# Intelligence Explosion Monitoring

**Tag**: Security

## What it is
Metrics and monitoring systems to detect when AI systems begin contributing more to their own improvement than human researchers. Tracks acceleration in capabilities against predefined thresholds that would trigger emergency protocols before reaching full AGI.

## Why it matters
- Provides early warning when AI progress enters exponential growth phases
- Enables intervention before rapid capability jumps make control more difficult
- Detects when labs might be incentivized to keep breakthroughs secret

## Current state
- **Status**: Idea
- **Bottlenecks**: Not specified

## Who's working on it
- Not specified

## Sources
- [Peregrine 2025 #84: Intelligence Explosion Monitoring](../sources/peregrine-2025/interventions/peregrine-084.md)
