# AI safety talent pipeline

**Tag**: Society

## What it is
Expanding the pool of AI safety researchers and practitioners through two complementary approaches:

**Accelerated training**: Programs to train and deploy AI security experts who understand both technical details and timeline urgency, demonstrate exceptional competence, and maintain a global perspective. Aims to cultivate 100-1000 experts by end of 2027. Requires compressing typical years-long training into rapid pathways.

**Researcher buyout**: Grants of $2-5 million per researcher to redirect top AI talent from frontier capabilities work to security research. Goal is to significantly shift distribution of elite technical talent during the critical 2025-2027 window.

## Why it matters
- Not enough qualified people working on AI safety who understand both technology and urgency
- Best researchers work on capabilities because that's where money and prestige are
- Safety research is talent-constrained
- Traditional training timelines may be too slow if AI timelines are short
- Directly paying researchers to switch fields could shift capabilities-safety balance during critical period

## Current state
- **Status**: Idea
- **Bottlenecks**: Compressing training timelines; identifying and recruiting elite researchers; funding scale

## Who's working on it
- Not specified

## Sources
- [Peregrine 2025 #31: AI Security Expert Development](../sources/peregrine-2025/interventions/peregrine-031.md)
- [Peregrine 2025 #37: Researcher Buy-Out](../sources/peregrine-2025/interventions/peregrine-037.md)
