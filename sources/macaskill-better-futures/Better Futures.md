[  
![Forethought](https://www.forethought.org/logo/Forethought-Logo.svg)](https://www.forethought.org/)


## 1. The basic case

[](https://www.forethought.org/research/introducing-better-futures#1-the-basic-case "Link to heading")

Suppose we want the future to go better. What should we do?

One prevailing approach is to try to avoid roughly _zero-value_ futures: reducing the risks of human extinction or of misaligned AI takeover.

This essay series will explore an alternative point of view: _making good futures even better_. On this view, it’s not enough to avoid near-term catastrophe, because the future could still fall far short of what’s possible. From this perspective, a near-term priority — or maybe even _the_ priority — is to help achieve a truly _great_ future.

That is, we can make the future go better in one of two ways:

1. _Surviving_: Making sure humanity avoids near-term catastrophes (like extinction or permanent disempowerment).[1](https://www.forethought.org/research/introducing-better-futures#user-content-fn-1)
    
2. _Flourishing_: Improving the quality of the future we get if we avoid such catastrophes.
    

This essay series will argue that work on _Flourishing_ is in the same ballpark of priority as work on _Surviving_. The basic case for this appeals to the _scale_, _neglectedness_ and _tractability_ of the two problems, where I think that _Flourishing_ has greater scale and neglectedness, but probably lower tractability. This section informally states the argument; the supplement (“[The Basic Case for Better Futures](https://www.forethought.org/research/supplement-the-basic-case-for-better-futures)”) makes the case with more depth and precision.

### Scale

[](https://www.forethought.org/research/introducing-better-futures#scale "Link to heading")

First, scale. As long as we’re closer to the ceiling on _Survival_ than we are on _Flourishing_ — if there is more room for improvement on the latter — then _Flourishing_ has greater scale.

To illustrate, suppose you think that our chances of survival this century are reasonably high (greater than 80%) but that, if we survive, we should expect a future that falls far short of how good it could be (less than 10% as good as the best feasible futures). These are close to my views; the view about _Surviving_ seems widely-held,[2](https://www.forethought.org/research/introducing-better-futures#user-content-fn-2)

 and Fin Moorhouse and I will argue in essays 2 and 3 for something like that view on _Flourishing_. If so, there’s more room to improve the future by working on _Flourishing_ than by working on _Surviving_.

![Chart comparing value loss from survival vs flourishing risks: small red area shows 20% extinction risk, large blue area shows 72% value loss from non-flourishing, demonstrating flourishing has 36x greater scale](https://images.ctfassets.net/4owxfjx3z3if/41DrT8Ehvh1OBpXkWvX82K/c2e8dccdd840f41a66013cf8e55e3c22/surviving-vs-flourishing-value-comparison.png?w=3840&q=75&fm=webp "Comparing the scale of surviving and flourishing")

Comparing the scale of surviving and flourishing

## Image

On these numbers, if we completely solved the problem of not-_Surviving_, we would be 20 percentage points more likely to get a future that's 10% as good as it could be. Multiplying these together, the difference we’d make amounts to 2% of the value of the best feasible future.

In contrast, if we completely solved the problem of non-_Flourishing_, then we’d have an 80% chance of getting to a 100%-valuable future. The difference we’d make amounts to 72% of the value of the best feasible future — 36 times greater than if we’d solved the problem of not-_Surviving_. Indeed, increasing the value of the future given survival from 10% to just 12.5% would be as good as wholly eliminating the chance that we don't survive.[3](https://www.forethought.org/research/introducing-better-futures#user-content-fn-3)

And the upside from work on _Flourishing_ could plausibly be much greater still than these illustrative numbers suggest. If _Surviving_ is as high as 99% and _Flourishing_ as low as 1%, then the problem of non-_Flourishing_ is almost 10,000 times as great in scale as the risk of not-_Surviving_. So, for priority-setting, the value of forming better estimates of these numbers is high.[4](https://www.forethought.org/research/introducing-better-futures#user-content-fn-4)

|**Surviving (probability of avoiding a ~zero-value future)**|**Flourishing (% value of the future if we avoid a ~zero-value future)**|**Relative scale of non-Flourishing to not-Surviving**|
|---|---|---|
|0.8|0.1|36|
|0.95|0.05|361|
|0.99|0.01|9801|

Comparing the value of fully solving non-_Flourishing_ with fully solving not-_Surviving_, given different default estimates of _Surviving_ and _Flourishing_.

A further argument about scale comes from considering _which_ worlds are saved by working on _Survival_, or improved by working on _Flourishing_. Conditional on successfully preventing an extinction-level catastrophe, you should expect _Flourishing_ to be (perhaps much) lower than otherwise, because a world that needs saving is more likely to be uncoordinated, poorly directed, or vulnerable in the long run. So the value of increasing _Survival_ is lower than it would first appear. On the other hand, there is little reason to believe that worlds where you successfully increase _Flourishing_ are ones in which the chance of _Surviving_ is especially low. So this consideration differentially increases the value of work on _Flourishing_.[5](https://www.forethought.org/research/introducing-better-futures#user-content-fn-5)

### Neglectedness

[](https://www.forethought.org/research/introducing-better-futures#neglectedness "Link to heading")

Second, neglectedness. Most people in the world today, on both their self-interest and their moral views, care much more about avoiding near-term catastrophe (including risks to the lives of themselves and their family), than they do about long-term flourishing. So we should expect at least some aspects of _Flourishing_ to be much more neglected, by the wider world, than risks to _Survival_.[6](https://www.forethought.org/research/introducing-better-futures#user-content-fn-6)

 Work on _Flourishing_ currently seems more neglected among those motivated by longtermism, too.

This neglect arises in part because the risks of failure in _Flourishing_ are often much more subtle than the risk of near-term catastrophe. The future could even be truly wonderful, compared to the current world, yet still fall radically short of what’s possible. Ask someone to picture utopia, and they might describe a society like ours, but free from its most glaring flaws, and abundant with those things we currently want. But the difference in value between the world today and that common-sense utopia might be very small compared to the difference between that common-sense utopia and the best futures we could feasibly achieve.

![Value spectrum showing existential catastrophe at zero, present day and common-sense utopia clustered near the low end, with vast unexplored space between utopia and near-best futures at value 1](https://images.ctfassets.net/4owxfjx3z3if/5vLIUnOs6bULRnxNrOkdCW/0d8a4775e7a98d2a422555a1852885eb/future-value-spectrum-diagram.png?w=3840&q=75&fm=webp "Comparing the value of possible futures. The “present-day” future means a future which extends the most relevant features of the world today, for as long as the common-sense utopia lasts, and considering human lives only.")

Comparing the value of possible futures. The “present-day” future means a future which extends the most relevant features of the world today, for as long as the common-sense utopia lasts, and considering human lives only.

## Image

### Tractability

[](https://www.forethought.org/research/introducing-better-futures#tractability "Link to heading")

The tractability of work to improve _Flourishing_ is less clear; essays [4](https://www.forethought.org/research/persistent-path-dependence) and [5](https://www.forethought.org/research/how-to-make-the-future-better) will discuss this more. I see this as the strongest argument against the better futures perspective, and the reason why I don’t feel confident that work on _Flourishing_ is higher-priority than work on _Surviving_, rather than merely in the same ballpark.

But at the very least I think we should _try to find out_ how tractable work to improve _Flourishing_ is. Some promising areas include: reducing the risk of human concentration of power; ensuring that advanced AI is not merely corrigible but also loaded with good, reflective values; and improving the quality of decisions that structure the post-AGI world, including around space governance and the rights of digital beings.

![](https://www.forethought.org/graphics/sm/sm10.svg)

## 2. The series

[](https://www.forethought.org/research/introducing-better-futures#2-the-series "Link to heading")

In the rest of the series, I argue:

- **We are unlikely to get a flourishing future by default** even if we avoid catastrophe, because a flourishing future is a narrow target ([essay 2](https://www.forethought.org/research/no-easy-eutopia#2-eutopia-is-fragile)) and it’s unlikely that future people will hone in on that target ([essay 3](https://www.forethought.org/research/convergence-and-compromise#2-will-most-people-aim-at-the-good))[7](https://www.forethought.org/research/introducing-better-futures#user-content-fn-7)
    
- **It’s possible to have persistent positive impact on how well the long-run future goes other than by avoiding catastrophe** ([essay 4](https://www.forethought.org/research/persistent-path-dependence))
    
- **There are concrete things we could do to this end, today** ([essay 5](https://www.forethought.org/research/how-to-make-the-future-better#2-keeping-our-options-open))
    

There’s a lot I _don’t_ cover, too, just because of limitations of space and time. For an overview, see this footnote.[8](https://www.forethought.org/research/introducing-better-futures#user-content-fn-8)

![](https://www.forethought.org/graphics/sm/sm02.svg)

## 3. What Better Futures is not

[](https://www.forethought.org/research/introducing-better-futures#3-what-better-futures-is-not "Link to heading")

Before we dive in, I want to clarify some possible misconceptions.

First, this series doesn’t require accepting consequentialism, which is the view that the moral rightness of an act depends wholly on the value of the outcomes it produces. It’s true that my focus is on how to bring about good outcomes, which is the consequentialist _part_ of morality. But I don’t claim you should always maximize the good, no matter the self-sacrifice, and no matter what means are involved. There are lots of other relevant moral considerations that should be weighed when taking action, including non-longtermist considerations like special obligations to those in the present (which generally favour interventions to increase _Survival_). But long-term consequences are important, too, and that’s what I focus on.[9](https://www.forethought.org/research/introducing-better-futures#user-content-fn-9)

, [10](https://www.forethought.org/research/introducing-better-futures#user-content-fn-10)

  

Second, this series doesn’t require accepting moral realism, which I’ll define as the view that there are objective facts about value, true independently from what anyone happens to think.[11](https://www.forethought.org/research/introducing-better-futures#user-content-fn-11)

 Whether or not you think there are objective moral facts, you can still care about how the future goes, and worry that the future will not be in line with your own values, or the values you’d have upon careful reflection. I’m aware that this series often uses realist-flavoured language, which is simpler and reflects how I personally tend to think about ethics. But we can usually just translate between realism and antirealism: where the realist speaks of the “correct” moral view, the antirealist could think about “the preferences I’d have given some ideal reflective process”.[12](https://www.forethought.org/research/introducing-better-futures#user-content-fn-12)

Third, this series isn’t in opposition to work on preventing downsides, like “s-risks” —  risks of astronomical amounts of suffering, which also affect “_Flourishing_” rather than “_Survival_”. We should take such risks seriously: depending on your values and your takes on tractability, they might be the top priority, and their importance comes up repeatedly in the next two essays. The focus of this series, though, is generally on making good futures even better, rather than avoiding net-negative futures.[13](https://www.forethought.org/research/introducing-better-futures#user-content-fn-13)

Fourth, the better futures perspective doesn’t mean endorsing some narrow conception of an ideal future, as past utopian visions have often done. Given how much moral progress we should hope to make in the future, and how much we’ll learn about what’s even empirically possible, we should act on the assumption that we have almost no idea what the best feasible futures would look like. Committing today to some particular vision would be a great mistake.

A central concept in my thinking about better futures is that of _viatopia_, which is a state of the world where society can guide itself towards near-best outcomes, whatever they may be.[14](https://www.forethought.org/research/introducing-better-futures#user-content-fn-14)

 We can describe viatopia even if we have little conception of what the desired end state is. Plausibly, viatopia is a state of society where existential risk is very low, where many different moral points of view can flourish, where many possible futures are still open to us, and where major decisions are made via thoughtful, reflective processes. From my point of view, the key priority in the world today is to get us closer to viatopia, not to some particular narrow end-state. I don’t discuss this concept further in this series, but I hope to write more about it in the future.

With that, let’s jump in.

![](https://www.forethought.org/graphics/sm/sm13.svg)

Released on 3rd August 2025

## Citations

![](https://www.forethought.org/graphics/sm/sm01.svg)

[

### Better Futures

](https://www.forethought.org/research/better-futures)Article Series

Part 1 of 6

Suppose we want the future to go better. What should we do?

One approach is to avoid near-term catastrophes, like human extinction. This essay series explores a different, complementary, approach: improving on futures where we survive, to achieve a truly great future.

[No Easy Eutopia

](https://www.forethought.org/research/no-easy-eutopia)

1

_Surviving_ represents the probability of avoiding a near-total loss of value this century (an “existential catastrophe”), while _Flourishing_ represents the expected value of the future conditional on our survival.

2

Grace, Stewart, Sandkühler, Thomas, Weinstein-Raun, and Brauner, ‘[Thousands of AI Authors on the Future of AI](http://arxiv.org/abs/2401.02843)’; Besiroglu, [‘Ragnarök Series—results so far’](https://www.metaculus.com/questions/2568/ragnar%25C3%25B6k-seriesresults-so-far/); Karger, Rosenberg, Jacobs, Hadshar, Gamin, Smith, McCaslin, Thomas, and Tetlock, [‘Forecasting Existential Risks’](https://forecastingresearch.org/xpt).

3

The same is true if we think about absolute changes, too. Suppose we could increase by one percentage point either the chance of survival or the value of the future given survival. Given the numbers we’re using, increasing the value of the future given survival would be 8 times more valuable.

4

And it suggests that the _expected_ relative scale of _Flourishing_ might be larger than your median estimate, if you put some meaningful probability on the more extreme ratios.

5

This point is from Trammell, ‘[Which World Gets Saved](https://forum.effectivealtruism.org/posts/cYf6Xx8w7bt9ivbon/which-world-gets-saved)’. It is discussed in more depth in the ‘[The Basic Case for Better Futures](https://www.forethought.org/research/supplement-the-basic-case-for-better-futures)’

6

Of course, many near-term-focused altruistic efforts will likely have some positive knock-on effects for the long-term future. But there are likely to be some ways of improving the future that seem important from a long-term perspective and are neglected by society at large.

7

Both essays are co-authored with Fin Moorhouse.

8

First, I don’t discuss how high our chance of Survival is. For a small sample of the extant discussion, see: [‘Ord, ‘The precipice: existential risk and the future of humanity](https://theprecipice.com/)’, Carlsmith, ‘[Is Power-Seeking AI an Existential Risk?](http://arxiv.org/abs/2206.13353)’, and footnote 2 above.

Second, I don’t discuss whether getting to a great future intrinsically requires following some good (e.g. just or legitimate) _process_, as well as achieving some good long-run outcome.

Third and finally, I am aware that most of this series leans strongly abstract and philosophical. You might reasonably worry about being led astray by this kind of argumentation; I do too. Most of this series is trying to follow the abstract arguments where they lead. But I’m not arguing, all-things-considered, to abandon common sense, especially if the abstract arguments make recommendations which seem common-sensically wrong or harmful.

9

You could have a radical non-consequentialist view which has no conception of the good, or on which making outcomes better is essentially morally irrelevant. If so, then this series might be of little interest to you. However, I suspect that any plausible radical non-consequentialist view will end up with some surrogate notion of “the good”, in order to make sense of claims like “a future with a trillion tortured people is worse than a future with a billion somewhat unhappy people,” and much of my discussion could be ported over, using that surrogate concept. I’ll also note that at the very least you shouldn’t be _certain_ in the radical non-consequentialist position and, in my view, you should take moral uncertainty into account in your decision-making.

10

“Long-term” here need not mean “trillions of years”. Even if one restricts one’s attention to much shorter timescales, the better futures perspective is still relevant and important.

11

Moral philosophers sometimes drop the adjective “objective” in the definition of moral realism, such that subjectivism is a form of “non-robust” moral realism

12

Your sympathy to realism or antirealism might affect what views you come to on the questions of “easy eutopia” and “convergence” that are discussed in the next two essays. But antirealism does not make the discussion as a whole irrelevant.

13

Moreover, in draft work, I estimate that, under moral uncertainty, bads like suffering should get _some_ more weight than goods like happiness, but not vastly more weight; my personal estimate ends up around 4x–10x. Given this, and given that I expect the creation of bads to be less common than foregone opportunities to produce goods, and given the difficulty of tractably reducing s-risks (which has led many s-risk-oriented folk to conclude that they are “clueless”; see Cook and Taylor, ‘[Leadership change at the Center on Long-Term Risk](https://forum.effectivealtruism.org/posts/YE3tdpE6JdiWRqqKx/leadership-change-at-the-center-on-long-term-risk)’. I currently suspect that work to capture upside is generally higher-priority than work on s-risks, although I’m far from certain.

14

The idea of the “long reflection” or “great deliberation” is one proposal for what viatopia might look like, but there could be others.

[![Forethought](https://www.forethought.org/logo/Forethought-Logo.svg)](https://www.forethought.org/)
