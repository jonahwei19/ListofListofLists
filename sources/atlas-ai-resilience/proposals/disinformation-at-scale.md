# AI-Scaled Disinformation

**Source**: Atlas AI Resilience Gap Map
**URL**: (internal document from Atlas Computing)

## Quoted passage

> gap: AI generated content can scale current approaches to mis- and disinformation, eroding humans' ability to evaluate the veracity of claims. We do not yet either sufficient tools for maintaining epistemic hygine or validating evidence that may be needed.

> claim: we need tools to help reach consensus as information warfare drives divisiveness

> We should have tools like the Habermas Machine or "community notes" deployed everywhere

> claim: we specifically need ways to connect claims to ground-truth to mitigate risks from disinformation

> Develop cryptographic provenance, authentication standards for digital content (including C2PA and similar frameworks), and robust scalable trust networks (similar to DNS)

> claim: effort in this direction is limited by awareness of epistemic risks

> Organizations should track and build reputation for understanding, mitigating, and protecting against specific risks exacerbated by AI.

> claim: we need early detection of threats to epistemic security

> Someone should propose simple-yet-effective modifications to existing organizations and workflows (e.g. have a suicide hotline partner with sociologists and expert AI users to create resources related to LLM-induced psychosis or check information diets in discovery processes in conflict mediation) to enable early detection of threats

> claim: we need an information warfare test range to develop detection and defensive tools to improve resilience

> someone should leverage large numbers of AI agents to develop standardized environments at the scale of a digital twin for a large fraction of a social media platform for experiments like this

## Tags
Society
