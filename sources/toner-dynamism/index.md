# Helen Toner: Dynamism for AI Safety

**Source:** [Rising Tide Substack](https://helentoner.substack.com/) (2025)

**Files in this folder:**
- `In search of a dynamist vision for safe superhuman AI.md` - Main dynamism essay
- `The core challenge of AI alignment is steeribility.md` - Alignment = steerability
- `Taking Jaggedness seriously.md` - On AI capabilities
- `Unresolved debates around the future of AI.md` - Open questions

---

## Main Thesis

Helen Toner applies Virginia Postrel's "dynamism vs stasis" framework to AI safety debates. The core insight: criticisms of AI safety often miss the mark because they use wrong dichotomies (pro-tech vs anti-tech, risk-embracing vs risk-averse). The better dichotomy is dynamism (creation, discovery, competition) vs stasis (regulated, engineered world valuing stability and control).

**Key claim**: Some AI safety policies have stasist tendencies, but AI itself also threatens dynamism. We need solutions that address AI risks *without* collapsing into stasis.

---

## Key Concepts

### Dynamism vs Stasis

From Virginia Postrel's *The Future and Its Enemies* (1998):

- **Dynamism**: "a world of constant creation, discovery, and competition"
- **Stasis**: "a regulated, engineered world... [that values] stability and control"

Postrel's dynamism values:
- Decentralized experimentation
- Spontaneous adjustment
- Creativity and risk-taking
- Open-ended futures

### Stasist Tendencies in AI Safety

Toner identifies several:

1. **Concentration assumption**: The widespread (long-unquestioned) assumption that fewer leading AI projects is better
2. **Nonproliferation focus**: Preventing misuse by limiting who has access to technology
3. **Licensing regimes**: Top-down control over who can train frontier models
4. **Theory of victory thinking**: Working backward from pre-specified end states
5. **Vulnerable World Hypothesis**: Bostrom's paper suggesting ubiquitous surveillance as solution

### But AI Also Threatens Dynamism

Criticizing stasist solutions doesn't negate the problems:
- Catastrophic misuse
- Catastrophic misalignment
- Concentration of power
- Gradual disempowerment

> "A world with AI calling the shots and humans either dead or disempowered would not count as real dynamism, even if there were a vibrant AI economy of invention and creation."

### Alignment = Steerability

Toner proposes substituting "steerability" for "alignment":

- Clearer why we want steerable systems
- Separates "steerable at all" from "steered to where"
- Avoids connotations that there's an obvious reference point to align to
- Makes room for the "whose values?" question as separate from the technical problem

### Dynamist Rules (from Postrel)

1. Allow individuals to act on their own knowledge
2. Apply to simple, generic units that combine in many ways
3. Permit credible, understandable, enduring commitments
4. Protect criticism, competition, and feedback
5. Establish frameworks within which nested, competing frameworks can exist

---

## Relevance to Our Tiling

### Where Toner Would Push Back

Our tiling may have stasist tendencies:
- Kill chains focus on control points and stopping bad outcomes
- Interventions often assume top-down coordination
- Less emphasis on dynamist alternatives

### What Toner Would Add

1. **Concentration of power** as distinct risk (now increasingly included in x-risk breakdowns)
2. **Transparency** as dynamist intervention
3. **Third-party audit ecosystems** for credible commitments
4. **Open models** for decentralized experimentation
5. **Differential technological development** (cites Vitalik's d/acc)

### Mapping to Our Categories

| Toner Concept | Our Category | Notes |
|---------------|--------------|-------|
| Catastrophic misuse | AI-Enabled WMD | Direct mapping |
| Catastrophic misalignment | Rogue AI | Direct mapping |
| Concentration of power | Lock-in | Central concern |
| Gradual disempowerment | Flourishing | Threat to dynamism |

---

## Key Quotes

"I don't think AI safety is inherently stasist. But I do think that a subset of the policies championed by the AI safety community are quite stasist, and that the community overall can have a stasist vibe."

"It's hard to get more stasist—focusing on stability and control—than ubiquitous real-time worldwide surveillance."

"If we handle [catastrophic risks] by massively concentrating power, we haven't succeeded. For the future to actually go well, we will need to find our way to some new equilibrium that allows for decentralized experimentation, spontaneous adjustment, creativity, and risk-taking."

"Thinking in terms of how AI might threaten a dynamic future, one thing that becomes clear is that preventing the worst-case scenarios is only the first step."

"We need to be able to critique solutions without being blind to the underlying problems."

---

## Contrast with Other Experts

### vs Nielsen

Both emphasize ongoing institutional challenges over one-time solutions. But:
- Nielsen focuses on market vs non-market safety
- Toner focuses on dynamism vs stasis
- Nielsen's coceleration; Toner's dynamist rules

### vs Vitalik

Toner explicitly cites Vitalik's d/acc as compatible with dynamism. Both:
- Emphasize differential technological development
- Skeptical of solutions that concentrate power
- Value decentralization and openness

### vs Carlsmith (Otherness)

Less overlap. Both skeptical of pure control framings, but:
- Carlsmith's philosophical depth about AI relationship
- Toner's policy-focused lens on institutional design

---

## Background

Helen Toner is a former OpenAI board member (involved in the November 2023 Sam Altman firing). Previously at Georgetown's Center for Security and Emerging Technology (CSET) and Open Philanthropy. Her Substack "Rising Tide" launched in 2025.

---

*Last updated: 2026-01-11*
