# Risk-Model Evaluation

**Source**: Peregrine 2025, Proposal #52
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Specific technique

## What it is
Develop evaluation frameworks for AI risk assessment systems by creating methodologies to identify, classify and prioritize potential AI mistakes based on their consequences. These evaluations would test how well risk models detect both obvious and subtle errors, especially in high-stakes contexts where mistakes could have severe impacts. The frameworks would quantify both false positive and false negative rates, enabling trade-offs between intervention frequency and risk exposure.

## Why it matters
Creates the foundation for reliable triage systems that focus human attention where it's most critically needed. Without this, risk assessment is ad-hoc and resources are misallocated.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Science
