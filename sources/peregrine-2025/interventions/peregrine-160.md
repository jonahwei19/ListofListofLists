# AI Lab Security

**Source**: Peregrine 2025, Proposal #160
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Field/category

## What it is
Improve high-assurance security across AI labs in general by pushing toward more consistent baselines (such as emerging frontier-lab and NIST-inspired security expectations). This requires several actions across various dimensions - from gaining management buy-in to recruiting specialized security talent and developing lab-specific security measures that can withstand increasingly sophisticated threats. Government-side interventions could be helpful but should be expected only after a moderate crisis occurs.

## Why it matters
Labs with inconsistent security create weak links in the ecosystem. A single breach at any major lab could release weights, training data, or safety research that enables bad actors. Baseline security standards raise the floor across the industry.

## Current state
- **Status**: Pilot
- **Who's working on it**: Not specified

## Tags
Security
