# Characterizing AI Risks with Evidence

**Source**: Peregrine 2025, Proposal #48
**Specificity**: Specific technique

## What it is
Focus on robust research that characterizes risks empirically with high validity, with a particular focus on evidence that could be used to inform policy decisions. The goal would be to give governments clear criteria for when to intervene. This research would aim to create benchmarks that establish clear quantitative thresholds for risks, and provide credible empirical evidence that would enable appropriate government action when AI capabilities increase.

## Why it matters
Policy decisions require evidence, not speculation. Currently, risk claims range from dismissive to apocalyptic with little empirical grounding. Research that produces clear, validated metrics for risk would give policymakers actionable criteria for intervention, rather than forcing them to choose between competing narratives.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Science
