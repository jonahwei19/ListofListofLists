# Flexible Hardware for AI Governance

**Source**: Peregrine 2025, Proposal #71
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Specific technique

## What it is
Implement hardware-based governance mechanisms through Flexible Hardware-Enabled Guarantee (flexHEG) mechanisms that can be added to AI accelerators. This places each AI accelerator chip in a tamper-proof enclosure alongside a secure processor that monitors and filters all information and instructions, enabling multilateral, privacy-preserving verification and automated compliance. The design supports training run size limitations, verification of appropriate data usage, standardized safety evaluations, and controlled access to model weights. Updates must be signed by a quorum of international parties with rollback to a minimal baseline ruleset.

## Why it matters
Provides lab-level governance hardware to enforce organizational policies, access controls, and safe-use constraints within companies and cloud providers through technical rather than purely policy mechanisms.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Security
