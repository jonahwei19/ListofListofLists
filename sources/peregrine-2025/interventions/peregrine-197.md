# Foundations of Cooperative Agency Research

**Source**: Peregrine 2025, Proposal #197
**Specificity**: Field/category

## What it is
Establish if specific propensities and capabilities built into AI agents can reliably produce good outcomes, or if the infrastructure around the agents matters more than their internal design. Fundamental research to determine whether creating inherently "cooperative agents" is a meaningful framing. This research has implications for model specifications and AI constitutions.

## Why it matters
The field lacks clarity on whether safety comes from agent internals (values, training) or environmental constraints (oversight, containment). Answering this question determines where to allocate limited safety resources.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Science
