# Training Data Attribution

**Source**: Peregrine 2025, Proposal #1
**Specificity**: Specific technique

## What it is
Develop scalable methods to understand how specific training examples influence model behaviors, providing insight into why models exhibit certain tendencies and how these might be modified. This involves scaling techniques like influence functions, combining them with AI agents that process and explain the resulting patterns, and creating tools to simulate counterfactual training scenarios. Attribution technology would enable more targeted interventions to address safety issues by modifying training data instead of relying on post-training alignment techniques.

## Why it matters
Current alignment approaches rely heavily on post-training interventions (RLHF, fine-tuning) without understanding which training data caused problematic behaviors. If you can trace behaviors back to specific training examples, you can address alignment issues at the source rather than patching symptoms. This also enables verification of alignment claims and potential regulatory frameworks for training processes.

## Current state
- **Status**: Research
- **Who's working on it**: Anthropic (leading, though much remains unpublished), academic researchers

## Tags
Science
