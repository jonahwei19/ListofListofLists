# Go Beyond Pre-Paradigmatic Evaluation Frameworks

**Source**: Peregrine 2025, Proposal #51
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Field/category

## What it is
Achieve consensus on how to evaluate AI systems for security, especially as evaluation needs to transition from being locked inside labs to standardized external processes. This involves resolving crucial questions about whether evaluations will be qualitative or quantitative, crowdsourced or team-based, and what risk thresholds should trigger interventions.

## Why it matters
The absence of an agreed-upon framework for security evaluation is a key bottleneck for progress on regulatory frameworks or accountability mechanisms. Without answers to these fundamental questions, there's no common standard against which to measure AI systems or coordinate responses.

## Current state
- **Status**: Idea
- **Who's working on it**: Not specified

## Tags
Security
