# Scalable Oversight

**Source**: Peregrine 2025, Proposal #26
**Specificity**: Field/category

## What it is
Develop systems enabling humans to meaningfully understand and supervise increasingly powerful AI agents performing complex tasks. This work would bridge the capability gap between humans and advanced AI systems, allowing for meaningful human participation even as AI capabilities dramatically increase. Current AI outputs often lack confidence intervals, probability estimates, and clear explanations of reasoning, making oversight difficult. Scalable oversight aims to ensure humans can interpret, validate, and maintain control of systems even when those systems exceed human capabilities in specific domains.

## Why it matters
As AI systems become superhuman in various domains, direct human evaluation becomes impossible. Scalable oversight provides methods for humans to maintain meaningful control and verification even over systems they can't directly evaluate, preventing a situation where we must simply trust AI outputs we can't check.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified (multiple research groups)

## Tags
Science
