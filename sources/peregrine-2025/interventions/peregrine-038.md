# Scientific Understanding of Training AI

**Source**: Peregrine 2025, Proposal #38
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Field/category

## What it is
Develop a scientific understanding of the optimization processes used to train large AI systems. This agenda would focus on the causal factors in training and how they shape what models converge to, where the goal is to build predictive theories of optimization: when models will generalize (and when they won't), when failure modes like goal drift arise, and how interventions at training time can reliably steer outcomes. Understanding the relationship between training processes and emergent capabilities would enable more targeted interventions to improve safety.

## Why it matters
Currently, training is largely empirical: we run experiments and observe what happens. A scientific theory of training would enable prediction and control, allowing us to anticipate what capabilities or behaviors will emerge before training, and design training processes that reliably produce safe systems.

## Current state
- **Status**: Research
- **Who's working on it**: UK AI Safety Institute, researchers working on singular learning theory

## Tags
Science
