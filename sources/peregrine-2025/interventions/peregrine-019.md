# Unlearning Capabilities

**Source**: Peregrine 2025, Proposal #19
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Specific technique

## What it is
Conduct research to distinguish between unlearning knowledge (like removing specific content from training data) versus unlearning capabilities (like removing the ability to write malicious code). Knowledge unlearning has clear success metrics - a model should be indistinguishable from one never trained on certain content - but capability unlearning has no direct link between training data and resulting abilities.

## Why it matters
Simply removing dangerous knowledge from a model doesn't prevent it from deriving that knowledge or developing dangerous capabilities through other means. Understanding how to remove capabilities rather than just knowledge is essential for creating models that genuinely cannot perform harmful tasks, rather than models that just don't know certain facts.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Security
