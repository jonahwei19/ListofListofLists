# Complex Objective Functions

**Source**: Peregrine 2025, Proposal #16
**Specificity**: Field/category

## What it is
Create comprehensive incentive frameworks rather than relying on rule-based constraints for AI systems. This proposal suggests rewarding desired behaviors through carefully constructed objective functions instead of imposing restrictive guardrails which have proven largely ineffective in practice. The ideal end-goal would be to provide a portfolio of success stories to be compiled and shared across the industry. The hope is that such frameworks would provide a more robust foundation for aligning AI systems while also creating a compelling narrative that appeals to both sides of the political spectrum.

## Why it matters
Rule-based constraints (guardrails) are brittle: they can be jailbroken, circumvented, or fail in novel situations. Well-designed objective functions that make desired behaviors intrinsically rewarding could be more robust because the AI is optimizing for the right thing rather than being constrained from the wrong thing.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Science
