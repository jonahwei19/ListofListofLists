# End-to-End Harm Assessment

**Source**: Peregrine 2025, Proposal #43
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Specific technique

## What it is
Conduct comprehensive evaluations of harmful AI capabilities which involve full capability assessment frameworks, rather than focusing on multiple-choice tasks. Most current benchmarks are verifiable but limited, involving tests that don't capture how systems would execute complex, harmful sequential tasks in the real world. Methodologies are needed to evaluate "end-to-end harmful capability manifestation" - not just whether an AI can answer questions about harmful topics, but whether it can assist with ideation, planning, and execution of potentially dangerous activities.

## Why it matters
Current evals test whether models know dangerous information, not whether they can actually help execute harmful plans. A model might score low on biosecurity knowledge questions but still be capable of guiding someone through an attack. End-to-end assessment reveals actual harmful capability, not just knowledge.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Security
