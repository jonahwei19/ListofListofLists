# Probabilistic Programming

**Source**: Peregrine 2025, Proposal #8
**Specificity**: Field/category

## What it is
Scale promising academic approaches like Dreamcoder from the MIT Tenenbaum Lab, which show impressive results and favorable alignment properties but remain unscaled due to academia's focus on novelty rather than deployment. This would require finding experts at the intersection of GPU optimization and probabilistic programming languages to build specialized teams focused on making these approaches production-ready. With proper investment, these alternative AI paradigms could potentially deliver comparable benefits to transformer-based approaches within 3-5 years, but with significantly better security.

## Why it matters
Current transformer-based AI has inherent alignment challenges. Probabilistic programming offers an alternative paradigm with potentially better safety properties, including more interpretable reasoning and built-in uncertainty quantification. If scaled successfully, this could provide a safer path to capable AI systems, potentially justifying slowing transformer scaling.

## Current state
- **Status**: Research
- **Who's working on it**: MIT Tenenbaum Lab, academic researchers

## Tags
Science
