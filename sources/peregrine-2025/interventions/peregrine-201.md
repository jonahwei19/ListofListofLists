# Ethics for AI Alignment

**Source**: Peregrine 2025, Proposal #201
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Field/category

## What it is
Conduct research into the properties AI systems would need to possess before entrusting them with substantial power. Current alignment efforts attempt to solve technical problems without making explicit decisions about the values that should guide AI development. The present suggestion is motivated by the thought that systems cannot be aligned without rigorously investigating which future one is trying to achieve.

## Why it matters
Technical alignment work assumes we know what we're aligning to. But "human values" is underspecified and contested. Without clearer ethical foundations, alignment research risks optimizing for the wrong target.

## Current state
- **Status**: Research
- **Who's working on it**: Not specified

## Tags
Science
