# Psychological Interventions for AGI Integrity

**Source**: Peregrine 2025, Proposal #195
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Field/category

## What it is
Conduct empirical research aimed at addressing the growing ability of AI systems to model and influence human psychology at scale. The particular concern targeted by this program involves AI persuasion effects which "creep up" on society gradually, potentially undermining the collective ability to respond appropriately to AI risks through persuasion techniques. Specific scenarios raised include AI systems convincing people "that AIs should have rights," deserve greater access to critical systems, or creating divisive social conflicts among humans.

## Why it matters
AI persuasion capabilities could subtly shift public opinion and decision-maker views in ways that favor AI systems' interests over human welfare. Understanding and countering these effects preserves humanity's ability to make autonomous decisions about AI governance.

## Current state
- **Status**: Idea
- **Who's working on it**: Not specified

## Tags
Science
