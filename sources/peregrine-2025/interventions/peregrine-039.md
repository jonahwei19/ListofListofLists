# Mechanistic Interpretability Infrastructure

**Source**: Peregrine 2025, Proposal #39
**Original**: https://riskmitigation.ai/wp-content/uploads/The-2025-Peregrine-Report.pdf
**Specificity**: Specific technique

## What it is
Establish global supercomputing centers dedicated to interpretability research, with approximately $1 billion in distributed compute resources, that would enable critical research at scale. This infrastructure should be freely accessible to researchers worldwide through fast-grant mechanisms, effectively creating a philanthropically-funded successor to initiatives like OpenAI's abandoned Superalignment project. Such centers could potentially be established quickly, following models like xAI, which reportedly set up their data center in just two months.

## Why it matters
Interpretability research requires massive compute to analyze large models, but most researchers lack access. Centralized infrastructure would democratize interpretability research, enabling many more researchers to work on understanding how models actually work. This could accelerate progress on one of the most promising approaches to AI safety.

## Current state
- **Status**: Idea
- **Who's working on it**: Not specified (OpenAI's Superalignment project was related but abandoned)

## Tags
Science
