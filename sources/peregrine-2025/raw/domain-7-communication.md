Here are proposals #176-187 from Domain 7: Public Communication & Awareness (pages 49-51):

---

**#176 - Political Action Organization**
- **Goal:** Create dedicated political lobbying infrastructure specifically focused on AI security issues.
- **Mechanism:** Unlike traditional 501(c)(3) research organizations with restrictions on political activity, this entity would be explicitly designed for political influence as a 501(c)(4), enabling direct lobbying and political campaigns.
- **Who's working on it:** Not mentioned.

---

**#177 - Lobbying Support Tools**
- **Goal:** Enhance the effectiveness of existing lobbying organizations rather than competing with them.
- **Mechanism:** Develop standardized video content and presentation materials that showcase AI capabilities and risks, allowing lobbyists to reach thousands rather than conducting one-on-one demonstrations individually.
- **Who's working on it:** Not mentioned.

---

**#178 - Public Demonstration Projects (Usefulness)**
- **Goal:** Educate decision-makers who currently underestimate the power and potential of frontier AI systems.
- **Mechanism:** Create demos and launch campaigns about positive capabilities of frontier AI systems; create compelling demonstrations of beneficial applications alongside risk assessments for key stakeholders.
- **Who's working on it:** Not mentioned.

---

**#179 - Public Demonstration Projects (Future Risks)**
- **Goal:** Make AI risks tangible and personally relatable to individuals.
- **Mechanism:** Create personalized "Day After" scenarios that demonstrate AI risks in ways individuals can relate to (e.g., children's funds being threatened); amplify existing demonstrations that currently reach limited audiences.
- **Who's working on it:** Not mentioned (bottleneck noted as lack of resources and expertise to communicate demonstrations broadly).

---

**#180 - Concrete Risk Visualization**
- **Goal:** Make abstract global catastrophic risks more comprehensible to policymakers and the public.
- **Mechanism:** Connect risks to historical precedents with real-world impacts; example includes simulating how a present-day Tambora eruption (which caused the 1815-16 "Year Without Summer") would affect modern society, providing concrete reference points for understanding AI disruption scenarios.
- **Who's working on it:** Not mentioned.

---

**#181 - Build Intergovernmental Expertise**
- **Goal:** Create informed decision-making capacity within government and international institutions.
- **Mechanism:** Establish trusted expertise centers that provide authoritative briefings to policymakers on emerging AI capabilities and sectoral impacts.
- **Who's working on it:** Not mentioned.

---

**#182 - Popular Documentaries/Films**
- **Goal:** Reach broad audiences with AI risk communication while maintaining technical accuracy.
- **Mechanism:** Create compelling mainstream media content with substantial funding directed toward Hollywood professionals; produce a high-budget feature film with extensive input from alignment researchers (rather than direct advertising, which could be counterproductive).
- **Who's working on it:** Previous discussions with TV producers like Ron Moore mentioned, but not progressed to completion.

---

**#183 - Political Campaign Opposing Anti-Regulation Efforts**
- **Goal:** Shape public opinion on AI risks and build political will for governance.
- **Mechanism:** Launch a large-scale political campaign led by PR/communications experts involving significant media engagement similar to political campaigns, aiming to create public consensus that AI safety requires immediate action rather than becoming a partisan issue.
- **Who's working on it:** Not mentioned.

---

**#184 - Targeted Communications Campaign**
- **Goal:** Make key decision-makers more aware of challenges in AI security.
- **Mechanism:** Identify constituents who impact critical AI decisions; test various messages to determine which resonate most effectively; deliver targeted messages through appropriate channels (possibly recruiting marketing experts).
- **Who's working on it:** Not mentioned.

---

**#185 - Consensus-Building Evidence for AI Risk**
- **Goal:** Establish broad scientific consensus on AI risks comparable to climate change consensus.
- **Mechanism:** Create compelling, large-scale demonstrations and empirical studies that make AI risks vivid and understandable through concrete, uncontrived demonstrations rather than abstract theory; potentially through Nature-level publications focusing on both specific instances and broader patterns.
- **Who's working on it:** Apollo Research cited for related work (demo examples and scheming reasoning evaluations).

---

**#186 - Military and Government Awareness Campaigns**
- **Goal:** Slow or stall dangerous AI developments through administrative processes.
- **Mechanism:** Launch targeted social media campaigns showing concerning AI capabilities to key decision-makers in government and military chains of command; precisely target individuals with specific authority to delay approvals, permits, or authorizations critical to AI infrastructure expansion.
- **Who's working on it:** Not mentioned.

---

**#187 - Large-Scale Media Campaigns**
- **Goal:** Effectively reach target audiences with AI risk messaging.
- **Mechanism:** Launch comprehensive media strategies with substantial spending (e.g., $50 million annual spend suggested; $250 million noted as enabling a highly successful campaign comparable to a quarter of major corporate spending), without the "flattening restrictions of corporate communications style."
- **Who's working on it:** Not mentioned.
