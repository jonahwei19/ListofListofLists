## Domain 4: AI Governance & Policy Development (Proposals #87-114)

### Verification and Monitoring Infrastructure

**#87 - Incident Reporting**
- **Goal:** Create a standardized framework for documenting, analyzing, and sharing information about AI failures, misuse, or unexpected behaviors across organizations.
- **Mechanism:** Develop taxonomies for severity classification, enable cross-organizational learning from incidents, and facilitate coordinated responses to emerging threats. Similar to aviation safety reporting systems, includes whistleblower protections and timely disclosure requirements.
- **Who's working on it:** Not specified.

**#88 - Agent IDs and Reputation Systems**
- **Goal:** Enable AI agents to build and maintain reputations, disincentivizing development of AI agents that attack or exploit other agents.
- **Mechanism:** Implement identification mechanisms ("agent IDs") for AI systems that allow tracking behavior across interactions and building trust, analogous to how humans control exploitation via reputation mechanisms.
- **Who's working on it:** Not specified.

**#89 - Technical Governance Tools**
- **Goal:** Provide assurances about computational resource deployment and verify AI interactions.
- **Mechanism:** Develop tools for attribution and verification including methods to verify model identity, authenticate AI interactions, and track compute usage.
- **Who's working on it:** Not specified.

**#90 - Human Verification Systems**
- **Goal:** Provide a foundational security layer for protecting critical decision-making processes by distinguishing human actors from AI systems.
- **Mechanism:** Build robust systems for verifying human identity that can be continuously updated to counter increasingly sophisticated impersonation capabilities.
- **Who's working on it:** Not specified; references work by Greengard (2025), Meunier (2021), and Buterin (2025).

**#91 - Compute Governance**
- **Goal:** Create greater visibility into who controls computational resources, what systems are being developed, and potential capability thresholds being approached.
- **Mechanism:** Implement governance systems for global AI computation resources via technical and policy frameworks to track and potentially regulate high-capability computing, including monitoring systems for major compute clusters and transparency requirements for large-scale training runs.
- **Who's working on it:** Requires substantial government involvement.

---

### Aligning Commercial Incentives

**#92 - Enhanced Responsible Scaling Implementation**
- **Goal:** Transform existing Responsible Scaling Policies (RSPs) from theoretical frameworks into actionable implementation plans.
- **Mechanism:** Develop concrete, tested "if-then commitments" with ready-to-deploy protocols for when safety boundaries are approached, and build social mechanisms (including public accountability and transparency requirements) to ensure compliance.
- **Who's working on it:** METR (referenced for RSP framework).

**#93 - Barriers to Fine-tuning**
- **Goal:** Prevent proliferation of dangerous capabilities by making unauthorized fine-tuning of advanced AI models extremely difficult.
- **Mechanism:** Combine technical measures (secure hardware enclaves, cryptographic verification of model origins, detection systems for unauthorized derivatives) with policy frameworks establishing legal consequences for circumventing protections.
- **Who's working on it:** Not specified.

**#94 - Addressing AI Crawling Challenges**
- **Goal:** Establish ethical norms for training data collection and manage how AI systems access and index web content.
- **Mechanism:** Develop industry standards and technical solutions including consensus around acceptable crawling practices, technical enforcement mechanisms, and potentially compensation models for content creators.
- **Who's working on it:** Several groups taking independent action but lacking coordination.

**#95 - Training Data Licensing**
- **Goal:** Fairly compensate those whose data is used for AI training while providing nations and regulatory bodies leverage over AI development.
- **Mechanism:** Implement a regulated market for high-quality, difficult-to-replicate training data. Companies needing specialized data would need to comply with regulations to maintain access.
- **Who's working on it:** Not specified.

**#96 - Development-Phase Accountability Tools**
- **Goal:** Hold AI companies accountable during the critical model development period when many risks emerge.
- **Mechanism:** Create novel governance approaches for the internal, sensitive, and legally complex development processes, addressing significant "white space" in the oversight ecosystem.
- **Who's working on it:** Not specified.

**#97 - Accountability Frameworks**
- **Goal:** Incentivize responsible AI development through meaningful liability, similar to how aerospace safety improved when airlines faced liability.
- **Mechanism:** Develop robust accountability and traceability governance approaches as well as liability systems for labs.
- **Who's working on it:** Not specified; notes challenges getting international players like China to participate.

**#98 - Data Rights Systems**
- **Goal:** Create economic returns for individuals whose data trains AI models while ensuring quality data governance.
- **Mechanism:** Establish frameworks for compensating individuals whose data is used in AI training, particularly focusing on high-skilled or vulnerable sector labor contributions, with an "incentive compatible" system.
- **Who's working on it:** Not specified.

---

### Building Government and Regulatory Capacity

**#99 - Expert Collaboration**
- **Goal:** Prevent both monopolistic AI control and chaotic diffusion of dangerous AI capabilities.
- **Mechanism:** Assemble top economists and geopolitics experts to work intensively at a retreat to model AI governance challenges, then direct significant funding toward implementing identified solutions.
- **Who's working on it:** References the Booth Experts Panel as a model.

**#100 - Regulatory Talent**
- **Goal:** Improve the talent pool of people working in AI governance by placing competent, mission-aligned experts in government positions globally.
- **Mechanism:** Strategic talent allocation across critical agencies like the EU AI Office, various ACs (AI Centers), and other regulatory bodies, ensuring regulators have both technical understanding and motivation.
- **Who's working on it:** Not specified.

**#101 - Government AI Use**
- **Goal:** Help speed up government feedback loops, enabling more responsive regulation of AI-driven economic activity.
- **Mechanism:** Support governments in effectively using AI by developing specialized systems for policy implementation, monitoring, and regulatory oversight with accountability and transparency mechanisms.
- **Who's working on it:** Not specified.

**#102 - Academic-National Lab Cooperation**
- **Goal:** Create accelerated paths for transitioning academic concepts into operational security measures within critical timeframes.
- **Mechanism:** Adopt a hybrid model combining university-driven theoretical innovation with laboratory-driven practical deployment.
- **Who's working on it:** Not specified.

**#103 - Policy Connection**
- **Goal:** Ensure policy development is technically informed while remaining practically implementable.
- **Mechanism:** Build institutional bridges between technical experts and policymakers, develop shared vocabularies, educational resources, and collaboration mechanisms, including regular exchanges between technical teams and government officials.
- **Who's working on it:** Not specified.

**#104 - AI Security Institutes**
- **Goal:** Create both the possibility of better local enforcement and collaboration through established lines of communication.
- **Mechanism:** Establish security institutes in more major jurisdictions than currently exist.
- **Who's working on it:** Existing institutes referenced include UK AI Safety Institute.

**#105 - Risk Assessments**
- **Goal:** Redirect billions in existing funding toward relevant preparedness measures by influencing government resource allocation.
- **Mechanism:** Persuade governments to incorporate AI-driven catastrophic scenarios into official risk frameworks, engaging directly with government risk assessment agencies.
- **Who's working on it:** Not specified.

**#106 - Legal Authority Clarification**
- **Goal:** Produce ranked intervention plans that balance effectiveness with maintaining proper checks on power.
- **Mechanism:** Develop clear frameworks specifying which government agencies would have jurisdiction and authority to intervene in dangerous AI development, addressing who should be involved in oversight (Congress, public, international allies).
- **Who's working on it:** Not specified; notes different US agencies (DOD vs. DOE) would approach control very differently.

**#107 - Government Support Framework**
- **Goal:** Shape how governments support AI lab security.
- **Mechanism:** Create external lobbying bodies that understand both government regulation mechanics and the technical work involved in AI development and security.
- **Who's working on it:** Not specified; notes this idea currently lacks significant lab buy-in.

**#108 - Policy Studio/Competition**
- **Goal:** Address the issue of existing policy proposals being "too nebulous" by creating concrete, implementable legislation.
- **Mechanism:** Create a dedicated policy innovation hub that drafts specific legislation, regulations, and governance frameworks for AI safety, alongside clear explainers, examining past regulatory failures like SB 1047.
- **Who's working on it:** Not specified.

**#109 - Increased ARIA Support**
- **Goal:** Demonstrate viable paths for beneficial AI development without unnecessarily increasing risk.
- **Mechanism:** Increase support for UK's AI efforts, particularly ARIA's (Advanced Research and Invention Agency) work on hardware mechanisms and non-LLM based agent development approaches.
- **Who's working on it:** ARIA (UK).

**#110 - AI R&D Acceleration Threat Modeling**
- **Goal:** Move beyond vague concerns about "more R&D being bad" towards specific, actionable insights about acceleration dynamics.
- **Mechanism:** Investigate risks associated with acceleration of AI R&D, studying how quickly capabilities progress through various thresholds and whether preparedness can keep pace.
- **Who's working on it:** Not specified.

**#111 - AI Development Lifecycle Risk Management Framework**
- **Goal:** Specify how different technical and governance interventions complement each other to address risk scenarios.
- **Mechanism:** Develop comprehensive risk management approaches combining multiple safety interventions for "defense-in-depth," integrating measures spanning the entire AI development lifecycle from training methodology to ongoing monitoring, containment procedures, and continued alignment training.
- **Who's working on it:** Not specified.

**#112 - Government Data Centers**
- **Goal:** Provide secure facilities for hosting models deemed too dangerous for widespread distribution, or as platforms for government auditing and testing.
- **Mechanism:** Construct secure government facilities capable of hosting model weights and other sensitive AI assets, with access protocols tied to government procurement contracts creating incentives for compliance with safety metrics.
- **Who's working on it:** Not specified.

**#113 - AI Ownership**
- **Goal:** Avoid extreme inequality by determining how benefits from AI labor are shared across society when traditional employment may no longer be the primary distribution mechanism.
- **Mechanism:** Create governance frameworks for distributing ownership of AI-driven productivity. Potential approaches include public ownership of foundation models, mandated profit-sharing from AI deployment, or novel structures like data dividends.
- **Who's working on it:** References O'Keefe et al. (2020) and Data Dividends Initiative.

**#114 - Democratic Support**
- **Goal:** Provide essential infrastructure for addressing any technological threat including advanced AI systems.
- **Mechanism:** Support organizations focused on democratic accountability and institutional integrity, targeting multiple countries simultaneously with coordinated support for local democratic institutions.
- **Who's working on it:** References Effektiv Spenden in Germany as a model for specialized funds supporting democracy-strengthening organizations.
