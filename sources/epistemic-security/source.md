Top level goal:   
4\. People can coordinate…  
2\. …based on trustworthy information…  
3\. …that they receive or can access…  
1\. …from trustworthy sources.

**Defense-dominant epistemic infrastructure**  
**├── Source integrity (How much can you trust/validate the source of the content?)**  
			Goal: You know who they are and you have reason to trust them  
**│   ├── Source identity infrastructure** → you know who they are (e.g. [worldcoin](https://world.org/), [e-ID](http://e-estonia.com/solutions/estonian-e-identity/id-card))  
**│   ├── Source track records** → trust by induction: calibration or accuracy history  
**│   └── Trust propagation** → logic over transitive trust graphs, delegated assessment   
(e.g. [Stellar Consensus Protocol](https://stellar.org/learn/stellar-consensus-protocol))  
**├── Content integrity (How much can you trust/validate the content?)**  
**│   ├── Provenance evidence** Goal: given trust in the person, can you trust the content  
	(roughly: Person ⇔ device ⇔ measurement ⇔ claim ⇔ conclusions ⇔ iteration)  
								  ↕  
					     feedback  
**│   │   ├── Authentic capture** → tamper responsive secure sensors (e.g. [flexHEG](http://flexheg.com))  
			Secure cryptographic keys link person to measurement device  
**│   │   ├── Chain of custody** → cryptographic signing on measurement device (e.g. [C2PA](https://c2pa.org/))  
			Cryptographic protocol links device to measurement itself  
**│   │   └── Structured claims** → evidence links, assumptions maps (e.g. [debate maps](https://www.societylibrary.org/debate-mapping-program))  
			Logical decomposition, analysis, and combination of claims;   
contradiction detection  
**│   │   ├── Crowdsourced synthesis & annotation** → synthesis & feedback on claims (e.g.   
community notes, collaborative checking)  
**│   │   ├── Information condensation** → create schelling points for drawing conclusions   
(e.g. prediction markets, calibrated forecasting)  
**│   │   ├── Crowdsourced investigation** → identify and source data on unresolved claims  
**├── Distribution governance (How much can you incentivize the spread of true info?)**  
**│   ├── Amplification accountability →** punish bad info (e.g. recommendation   
auditing, transparency)  
**│   ├── Friction mechanisms** → disincentivize exploiting epistemic weaknesses   
(e.g. virality brakes, verification prompts)  
**│   └── Diversity injection** → incentivize good information sharing (e.g. filter bubble   
mitigation, amplify bridging)  
**│**	  Note: I do not think there are positive epistemic strengths to reward   
**└── Coordination infrastructure (How much can you incentivize convergence & action)**  
    **├── Preference legibility** → AI or human-mediated deliberation (e.g. Council AI,   
Polis)  
    **├── Common knowledge** → registries, claim databases (e.g. wikipedia, libraries)  
    **└── Commitment / finality** → pledges, accountability mechanisms (e.g.   
blockchains/ledgers, newspapers)

